import pandas as pd
import os
import torch
from transformers import pipeline
from datasets import Dataset

# **å…³é—­ symlinks è­¦å‘Š**
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

# **ç¡®ä¿ä½¿ç”¨ GPU**
device = 0 if torch.cuda.is_available() else -1
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=device)

# **ç”µå½±è¯„è®ºçš„åŸºç¡€åˆ†ç±»æ ‡ç­¾**
categories = ["Storyline", "Acting", "Cinematography", "Soundtrack", "Rewatchability"]

# **è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨**
file_names = [f"classified_file{i}.csv" for i in range(1, 11)]


# **æ‰¹é‡åˆ†ç±»å‡½æ•°**
def batch_classify(examples):
    results = classifier(examples["Review"], candidate_labels=categories, multi_label=True)

    # åªä¿ç•™æ¦‚ç‡ > 0.3 çš„ç±»åˆ«ï¼Œå¹¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
    target_list = [
        {label: round(score, 4) for label, score in zip(result["labels"], result["scores"]) if score > 0.3}
        for result in results
    ]

    return {"Target": [str(target) for target in target_list]}  # **è½¬æ¢ä¸ºå­—ç¬¦ä¸²**


# **éå†æ–‡ä»¶è¿›è¡Œå¤„ç†**
for file_name in file_names:
    if os.path.exists(file_name):
        print(f"ğŸ”„ å¤„ç†æ–‡ä»¶: {file_name} ...")

        # **åŠ è½½ CSV æ–‡ä»¶**
        df = pd.read_csv(file_name)

        # **è½¬æ¢ä¸º Hugging Face Dataset**
        dataset = Dataset.from_pandas(df)

        # **æ‰¹é‡å¤„ç†ï¼ˆæé«˜ GPU åˆ©ç”¨ç‡ï¼‰**
        dataset = dataset.map(batch_classify, batched=True, batch_size=16)

        # **è½¬æ¢å› Pandas DataFrame**
        df = dataset.to_pandas()

        # **ç¡®ä¿ `Target` åˆ—å·²æ›´æ–°ï¼Œå¹¶ä¿å­˜ä¸ºå­—ç¬¦ä¸²**
        df["Target"] = df["Target"].astype(str)

        # **ä¿å­˜åˆ†ç±»åçš„æ–‡ä»¶**
        output_file = f"processed_{file_name}"
        df.to_csv(output_file, index=False)
        print(f"âœ… å¤„ç†å®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {output_file}\n")

print("ğŸš€ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")
